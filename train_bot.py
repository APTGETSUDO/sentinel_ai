import os
import sys

# --- CONFIGURATION CLOUD (LINUX/GITHUB ACTIONS) ---
# 1. Force le CPU (Les serveurs GitHub gratuits n'ont pas de GPU)
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
# 2. R√©duit le bruit des logs TensorFlow
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
# --------------------------------------------------

import numpy as np
import pandas as pd
import yfinance as yf
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, BatchNormalization, Attention, Concatenate, Bidirectional
from tensorflow.keras.optimizers import Adam 
from sklearn.preprocessing import MinMaxScaler
import warnings

# Import du moteur de calcul (doit √™tre pr√©sent dans le m√™me dossier)
from quant_features import HedgeFundIndicators

warnings.filterwarnings("ignore")

# --- PARAM√àTRES ---
TICKER = "NVDA" 
SEQ_LEN = 60    
PREDICT_HORIZON = 1 

SERIES_COLS = ['Close', 'Log_Vol', 'VPIN', 'Returns', 'MFI', 'Tape_Speed']
CONTEXT_COLS = ['Hurst', 'Entropy', 'Volatility', 'ADX', 'Impulse_ATR', 'VBP_Density']

def create_sentinel_model(input_shape_series, input_shape_context):
    """Architecture IA (Standard Keras pour Linux)"""
    # Branche S√©rie
    input_series = Input(shape=input_shape_series, name="Time_Series_Input")
    x = Bidirectional(LSTM(64, return_sequences=True))(input_series)
    x = BatchNormalization()(x)
    attn = Attention()([x, x])
    x = LSTM(32, return_sequences=False)(attn)
    
    # Branche Contexte
    input_context = Input(shape=input_shape_context, name="Context_Input")
    y = Dense(16, activation="relu")(input_context)
    y = Dropout(0.2)(y)
    
    # Fusion
    combined = Concatenate()([x, y])
    z = Dense(32, activation="relu")(combined)
    output = Dense(1, activation="sigmoid")(z)
    
    model = Model(inputs=[input_series, input_context], outputs=output)
    
    # Optimiseur Standard (Pas Legacy, car on est sur Linux)
    model.compile(optimizer=Adam(learning_rate=0.001), loss="binary_crossentropy", metrics=["accuracy"])
    return model

def prepare_data(df):
    if df.empty or len(df) < SEQ_LEN + 10: return np.array([]), np.array([]), np.array([])

    scaler_series = MinMaxScaler()
    scaler_context = MinMaxScaler()
    
    # Gestion robuste des NaNs
    df = df.replace([np.inf, -np.inf], np.nan).dropna()

    try:
        # On s'assure que les colonnes existent
        avail_series = [c for c in SERIES_COLS if c in df.columns]
        avail_context = [c for c in CONTEXT_COLS if c in df.columns]
        
        if len(avail_series) != len(SERIES_COLS) or len(avail_context) != len(CONTEXT_COLS):
            print("‚ùå Colonnes manquantes dans quant_features.")
            return np.array([]), np.array([]), np.array([])

        data_series = scaler_series.fit_transform(df[avail_series])
        data_context = scaler_context.fit_transform(df[avail_context])
    except Exception as e: 
        print(f"‚ùå Erreur Scaling: {e}")
        return np.array([]), np.array([]), np.array([])
    
    X_series, X_context, y = [], [], []
    
    for i in range(SEQ_LEN, len(df) - PREDICT_HORIZON):
        X_series.append(data_series[i-SEQ_LEN:i])
        X_context.append(data_context[i])
        # Target : 1 si le prix monte, 0 sinon
        label = 1 if df['Close'].iloc[i + PREDICT_HORIZON] > df['Close'].iloc[i] else 0
        y.append(label)
        
    return np.array(X_series), np.array(X_context), np.array(y)

def main():
    print(f"üöÄ GITHUB RUNNER: D√©marrage Entra√Ænement sur {TICKER}...")
    
    # 1. T√©l√©chargement Donn√©es (Avec Retry Logic implicite via yfinance)
    try:
        df = yf.download(TICKER, period="2y", interval="1h", progress=False, auto_adjust=True)
        # Fix MultiIndex si n√©cessaire
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)
    except Exception as e:
        print(f"‚ùå Erreur YFinance: {e}")
        sys.exit(1) # Force l'√©chec pour le robot GitHub
    
    if df.empty:
        print("‚ùå Donn√©es vides.")
        sys.exit(1)
    
    # 2. Calcul Indicateurs
    print("‚öôÔ∏è Calcul des indicateurs quantitatifs...")
    try:
        df = HedgeFundIndicators.add_all_features(df)
    except Exception as e:
        print(f"‚ùå Erreur Features: {e}")
        sys.exit(1)

    # 3. Pr√©paration
    X_s, X_c, y = prepare_data(df)
    if len(X_s) == 0:
        print("‚ùå Pas assez de donn√©es pour l'entra√Ænement.")
        sys.exit(1)

    # Split 80/20
    split = int(len(y) * 0.8)
    X_s_train, X_s_val = X_s[:split], X_s[split:]
    X_c_train, X_c_val = X_c[:split], X_c[split:]
    y_train, y_val = y[:split], y[split:]
    
    print(f"üß† Entra√Ænement sur {len(y_train)} √©chantillons...")
    
    # 4. Mod√®le
    model = create_sentinel_model((SEQ_LEN, len(SERIES_COLS)), (len(CONTEXT_COLS),))
    
    # 5. Entra√Ænement "Clean Log"
    # verbose=2 est CRITIQUE pour GitHub : Affiche 1 ligne par √©poque au lieu d'une barre anim√©e
    model.fit(
        [X_s_train, X_c_train], y_train,
        validation_data=([X_s_val, X_c_val], y_val),
        epochs=15,          # Augment√© l√©g√®rement car serveurs rapides
        batch_size=32,
        verbose=2           # <-- L'optimisation cl√© pour les logs
    )
    
    # 6. Sauvegarde
    model.save("sentinel_v1.keras")
    print("‚úÖ MOD√àLE SAUVEGARD√â : sentinel_v1.keras")

if __name__ == "__main__":
    main()
